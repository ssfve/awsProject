import sys
from awsglue.transforms import *
from awsglue.utils import getResolvedOptions
from pyspark.context import SparkContext
from awsglue.context import GlueContext
from awsglue.job import Job

## @params: [JOB_NAME]
args = getResolvedOptions(sys.argv, ['JOB_NAME'])

sc = SparkContext()
glueContext = GlueContext(sc)
spark = glueContext.spark_session
job = Job(glueContext)
job.init(args["JOB_NAME"], args)

glueContext = GlueContext(SparkContext.getOrCreate())

df = glueContext.create_dynamic_frame.from_catalog(database="games-data-db", table_name="YOUR AWS GLUE RAW DATA TABLE NAME")


## The built-in transformation 'relationalize' is used to flatten the nested data structures. 
## This transofromation relationalizes a DynamicFrame and produces a collection of DynamicFrames 
## that are generated by unnesting nested columns and pivoting array columns. 
dfc = df.relationalize("root", "s3://YOUR CONSUMPTION DATA S3 BUCKET NAME")

## In this case, two tables 'root' and 'root_game_details' are generated.
flatdf = dfc.select('root')
flatdf2 = dfc.select('root_game_details')

## Group all the partitions into one file
flatdf_group = flatdf.coalesce(1)

## In the root_game_details DynamicFrame, rename column names that have dots as separator to names without dots. 
flatdf2_reformat_1 = RenameField.apply(flatdf2,"`game_details.val.game_name`", "game_name")
flatdf2_reformat_2 = RenameField.apply(flatdf2_reformat_1,"`game_details.val.high_score`", "high_score")
flatdf2_reformat_3 = RenameField.apply(flatdf2_reformat_2,"`game_details.val.purchased_item`", "purchased_item")
flatdf2_reformat_4 = RenameField.apply(flatdf2_reformat_3,"`game_details.val.purchases`", "purchases")

## Group all the partitions into one file
flatdf2_group = flatdf2_reformat_4.coalesce(1)

## Write the two flatten tables into the S3 consumption data bucket in parquet format.
glueContext.write_dynamic_frame.from_options(flatdf,connection_type="s3",connection_options = {"path":"s3://YOUR CONSUMPTION DATA S3 BUCKET NAME/parquet/players_data/"}, format = "parquet")
glueContext.write_dynamic_frame.from_options(flatdf2_reformat_4,connection_type="s3",connection_options = {"path":"s3://YOUR CONSUMPTION DATA S3 BUCKET NAME/parquet/games_data/"}, format = "parquet")

job.commit()
