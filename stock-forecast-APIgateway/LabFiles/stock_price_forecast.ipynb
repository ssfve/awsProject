{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Stock Price Prediction for Five Commodity-Based Companies  \n",
    "\n",
    "The investment fund management team would like to gain the ability to analyze time series data for stock price forecasting. As a first use case, they would like to start predicting the value of stocks of commodity-producing companies, based on historical data on some specific stocks.\n",
    "\n",
    "A script executed below will analyze the stock price history of the following commodity-based companies:\n",
    "\n",
    "- SuperPower Batteries (SUBAT): a company that produces clean energy by harvesting the enthusiasm emitted from educational gameplay; \n",
    "\n",
    "- Jack & Jill (JAJIL): this company is among the largest suppliers of bulk hill and island building materials;  \n",
    "\n",
    "- Voyager (VGER6): the largest Western manufacturer of the refined metals used in the construction of flying game drones;  \n",
    "\n",
    "- Sabre Feeds (SABRE): this company is one of the largest producers of grain-based animal feedstocks in the Americas;  \n",
    "\n",
    "- CloudAir (CLAIR): this company is considered the largest producer of rarified gasses in the world;  \n",
    "\n",
    "The data will be divided into 7 features for each day: lowest, highest, open, closed and adjusted close price, as well as volume and ticker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#ensure we have the latest pip\n",
    "%pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ensure our application has all of the libraries and versions it requires to run\n",
    "%pip install -U sagemaker\n",
    "%pip install botocore\n",
    "%pip install --upgrade awscli\n",
    "%pip install tensorflow\n",
    "%pip install s3fs\n",
    "%pip install matplotlib\n",
    "%pip install plotly\n",
    "%pip install nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load needed packages and utilities\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import os\n",
    "import json\n",
    "import nbformat\n",
    "import sys \n",
    "import _strptime\n",
    "import _datetime\n",
    "\n",
    "#import specific packages\n",
    "from datetime import date\n",
    "from plotly.subplots import make_subplots\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save the data bucket name here\n",
    "lab_data_bucket_name = \"<define the data bucket name here>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# listing the companies and gathering the data\n",
    "stock_list = [\"SUBAT.CQ\", \"JAJIL.CQ\", \"VGER6.CQ\", \"SABRE.CQ\", \"CLAIR.CQ\"]\n",
    "stock_data_url = f\"s3://{lab_data_bucket_name}/finance/stock/stock.parquet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Listing the companies and gathering the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#read stocks into data frame\n",
    "df = pd.read_parquet(stock_data_url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of convenience in the later steps, let's scale the adjclose for JAJIL now. This will result in better efficiency in the models as well as allow us to compare the prices in a relative way, which makes the performance easier to visualize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "index = df[df.symbol == \"JAJIL.CQ\"].index\n",
    "df.loc[index, \"adjclose\"] = scaler.fit_transform(df.loc[index].adjclose.values.reshape(-1, 1))\n",
    "df.loc[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import again here to make it available within the scope of this code block\n",
    "from datetime import datetime\n",
    "\n",
    "# Spliting the data into train and test\n",
    "def split_data(df, company_list, prediction_leght, startdate = '2018-01-02'):\n",
    "    \"\"\"\n",
    "        Receive a dataframe with one company or more, as well as a company list and split the data into train and test \n",
    "        by the date given as input for each company.\n",
    "        \n",
    "        Inputs:\n",
    "        - df: a dataframe containing at least timestamps and the target columns\n",
    "        - company_list: a list of company present in the df. They will be splited and formated\n",
    "        - prediction length: the number of timestamps that should be separeted as test data\n",
    "        - start_date: is the start of our dataset. Default is the startdate for BOVV11\n",
    "        \n",
    "        Returns:\n",
    "        2 dictionaries containing the train and test datasets for each company. The datasets contain just\n",
    "        the date column as well as the adjclose (target) column.\n",
    "    \"\"\"\n",
    "    startdate = datetime.strptime(startdate, '%Y-%m-%d').date()\n",
    "    \n",
    "    train = {}\n",
    "    test = {} \n",
    "\n",
    "    for company in company_list:\n",
    "        train[company] = df[(df.symbol == company) & (df.date > startdate)][:-prediction_length][[\"date\", \"adjclose\"]]\n",
    "        test[company] = df[(df.symbol == company) & (df.date > startdate)][-prediction_leght:][[\"date\", \"adjclose\"]]\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining the timespan to make it efficient and easier for the future\n",
    "timespan = 90\n",
    "prediction_length = timespan\n",
    "\n",
    "# Spliting the data\n",
    "train, test = split_data(df, stock_list, prediction_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload to S3\n",
    "\n",
    "In order to train a model in SageMaker, we need to first upload the data to an S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Saving the train and test data on data folder\n",
    "for stock in stock_list:\n",
    "    train[stock].to_csv(\"./data/train_{}.csv\".format(stock[:4].lower()), index = False)\n",
    "    test[stock].to_csv(\"./data/test_{}.csv\".format(stock[:4].lower()), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing general AWS session configuration\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "session = sagemaker.Session(default_bucket=lab_data_bucket_name)\n",
    "role = get_execution_role()\n",
    "\n",
    "bucket = session.default_bucket()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating specific configuration\n",
    "prefix = \"stock-price-forecast-project\"\n",
    "data_dir = \"./data\"\n",
    "paths = {}\n",
    "\n",
    "# Addressing the data on the disc\n",
    "train_key = os.path.join(data_dir, \"train_{}.csv\".format(\"jaji\"))\n",
    "test_key = os.path.join(data_dir, \"test_{}.csv\".format(\"jaji\"))\n",
    "\n",
    "# Path where the files will be saved\n",
    "train_prefix = \"{}/{}\".format(prefix, \"train_{}\".format(\"jaji\"))\n",
    "test_prefix = \"{}/{}\".format(prefix, \"test_{}\".format(\"jaji\"))\n",
    "\n",
    "# Uploading to S3\n",
    "paths[\"train\"] = session.upload_data(train_key, bucket = bucket, key_prefix = train_prefix)\n",
    "paths[\"test\"] = session.upload_data(test_key, bucket = bucket, key_prefix = test_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "\n",
    "Now, we will build two models and compare them to predict stock prices.  \n",
    "\n",
    "The timespan that we are interested in is 3 months, so for each model we are going to compare RMSE and MAE. We will also visualize the quality of the predictions by using a line graph with the prediction and real values for the last 90 days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Cut Forest Regressor - Baseline\n",
    "\n",
    "To start our model development task, it is a standard practice to have a baseline model so we can use it to compare future models, so we can see if we are making progress in refining our models.   \n",
    "\n",
    "For this task we will create three types of basic models:\n",
    "- Differentiation of the next row\n",
    "- Lag from the original target\n",
    "- Moving Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's concatanete the train and test dataframes to do just one feature engineering process\n",
    "df_rf = pd.concat([train[\"JAJIL.CQ\"], test[\"JAJIL.CQ\"]])\n",
    "df_rf.index = df_rf.date\n",
    "df_rf = df_rf.drop(\"date\", axis = 1)\n",
    "df_rf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's develop the features of these models..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Applying the diff to the data\n",
    "df_rf[\"adj_close_diff\"] = df_rf.diff()\n",
    "\n",
    "# Creating 10 lags for starting\n",
    "for i in range (5, 0, -1):\n",
    "    df_rf['t-' + str(i)] = df_rf.adjclose.shift(i)\n",
    "\n",
    "# Moving Avg of 2 weeks\n",
    "df_rf[\"rolling\"] = df_rf.adjclose.rolling(window = 14).mean()\n",
    "    \n",
    "df_rf.dropna(inplace = True)\n",
    "df_rf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a dataframe to work with, we can feed it into a basic random forest regressor. But first, let's split the data into train and test versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_rf = df_rf.iloc[:-timespan].drop(\"adjclose\", axis = 1)\n",
    "y_train_rf = df_rf.iloc[:-timespan].adjclose\n",
    "\n",
    "X_test_rf = df_rf.iloc[-timespan:].drop(\"adjclose\", axis = 1)\n",
    "y_test_rf = df_rf.iloc[-timespan:].adjclose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Checking\n",
    "X_train_rf.shape, X_test_rf.shape, y_train_rf.shape, y_test_rf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instanciating a Regressor and Training\n",
    "regressor_rf = RandomForestRegressor(n_estimators = 1000)\n",
    "\n",
    "# Training\n",
    "regressor_rf.fit(X_train_rf, y_train_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction_rf = regressor_rf.predict(X_test_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the predictions, let's transform it back to its un-scaled form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction_rf = scaler.inverse_transform(prediction_rf.reshape(1, -1))\n",
    "y_test_rf = scaler.inverse_transform(y_test_rf.values.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# RMSE\n",
    "rf_RMSE = np.sqrt(mean_squared_error(y_test_rf, prediction_rf))\n",
    "rf_RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MAE\n",
    "rf_MAE = mean_absolute_error(y_test_rf, prediction_rf)\n",
    "rf_MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's visualize this behaviour in a line graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trace1 = go.Scatter(x = X_test_rf.index, y = y_test_rf[0],\n",
    "                   mode = 'lines',\n",
    "                   name = 'Real Price')\n",
    "\n",
    "trace2 = go.Scatter(x = X_test_rf.index, y = prediction_rf[0],\n",
    "                    mode = \"lines\",\n",
    "                    name = \"Predicted Price\")\n",
    "\n",
    "layout = go.Layout(title = \"Real Price vs Predicted Price using Random Forest Regressor\",\n",
    "                   width = 1000, height = 600)\n",
    "\n",
    "fig = go.Figure(data = [trace1, trace2], layout = layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model with TensorFlow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting up the output path\n",
    "output_path = \"s3://{}/{}/output\".format(bucket, prefix)\n",
    "\n",
    "# Setting the instance type, batch size, and epoch size variables\n",
    "TF_FRAMEWORK_VERSION = '2.11.0'\n",
    "instancetype = \"ml.m5.xlarge\" \n",
    "batchsize = 32 \n",
    "epochsize = 25 \n",
    "\n",
    "regressor_tf = TensorFlow(\n",
    "    entry_point='train.py',\n",
    "    role=role,\n",
    "    framework_version=TF_FRAMEWORK_VERSION,\n",
    "    model_dir = False,\n",
    "    py_version='py39',\n",
    "    instance_type=instancetype,\n",
    "    instance_count=1,\n",
    "    output_path=output_path,\n",
    "    hyperparameters={\n",
    "        'batch-size':batchsize,\n",
    "        'epochs':epochsize})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "regressor_tf.fit(paths[\"train\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor_tf = regressor_tf.deploy(initial_instance_count=1, instance_type=instancetype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor_tf = Predictor(\n",
    "    endpoint_name=\"<Enter your endpoint name here>\",\n",
    "    sagemaker_session=sagemaker.Session(),\n",
    "    serializer=sagemaker.serializers.JSONSerializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make predictions, we need to first prepare the data with its lags. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_input_tf = train[\"JAJIL.CQ\"].adjclose.values.reshape(-1,1)\n",
    "test_input_tf = test[\"JAJIL.CQ\"].adjclose.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_volume = np.vstack((train_input_tf, test_input_tf))\n",
    "window = 30 # number of lags\n",
    "\n",
    "inputs = df_volume[df_volume.shape[0] - test_input_tf.shape[0] - window:]\n",
    "inputs = inputs.reshape(-1, 1)\n",
    "\n",
    "prediciton_lengh = df_volume.shape[0] - train_input_tf.shape[0] + window\n",
    "\n",
    "X_test = []\n",
    "\n",
    "for i in range(window, prediciton_lengh):\n",
    "    X_test_reshaped = np.reshape(inputs[i-window:i], (window, 1))\n",
    "    X_test.append(X_test_reshaped)\n",
    "\n",
    "X_test = np.stack(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor_tf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "try:\n",
    "    # new predictor\n",
    "    predictions_byte = predictor_tf.predict(X_test)\n",
    "    prediction_tf = np.array(predictions_byte[\"predictions\"])\n",
    "    print('1')\n",
    "except: \n",
    "    # reusing predictor\n",
    "    predictions_json = json.loads(predictions_byte)\n",
    "    prediction_tf = np.array(predictions_json[\"predictions\"])\n",
    "    print('2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scaling the predictions back\n",
    "prediction_tf = scaler.inverse_transform(prediction_tf).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# RMSE\n",
    "tf_RMSE = np.sqrt(mean_squared_error(y_test_rf[0], prediction_tf))\n",
    "tf_RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MAE\n",
    "tf_MAE = mean_absolute_error(y_test_rf[0], prediction_tf)\n",
    "tf_MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trace1 = go.Scatter(x = X_test_rf.index, y = y_test_rf[0],\n",
    "                   mode = 'lines',\n",
    "                   name = 'Real Price')\n",
    "\n",
    "trace2 = go.Scatter(x = X_test_rf.index, y = prediction_tf,\n",
    "                   mode = \"lines\",\n",
    "                   name = \"Predicted Price\")\n",
    "\n",
    "layout = go.Layout(title = \"Real Price vs Predicted Price using LSTM with Tensor Flow\",\n",
    "                   width = 1000, height = 600)\n",
    "\n",
    "fig = go.Figure(data = [trace1, trace2], layout = layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the result for the two models as well its scores, we can then move forward and explore the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Results\n",
    "\n",
    "Now that we have our models trained and evaluated on a test set, we can compare the metrics and use visualization to get insights on how good they are and how close they were to the forecast. \n",
    "\n",
    "Let's begin by comparing the metrics RMSE and MAE for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf_MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "metrics = {\"RMSE\": [rf_RMSE, tf_RMSE], \"MAE\": [rf_MAE, tf_MAE]}\n",
    "pd.DataFrame(metrics, index = [\"Random Forest\", \"LTSM\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trace1 = go.Scatter(x = X_test_rf.index, y = y_test_rf[0],\n",
    "                   mode = 'lines',\n",
    "                   name = 'Real Price')\n",
    "\n",
    "trace2 = go.Scatter(x = X_test_rf.index, y = prediction_rf[0],\n",
    "                   mode = \"lines\",\n",
    "                   name = \"Predicted Price RF\")\n",
    "\n",
    "\n",
    "trace3 = go.Scatter(x = X_test_rf.index, y = prediction_tf,\n",
    "                   mode = \"lines\",\n",
    "                   name = \"Predicted Price LSTM\")\n",
    "\n",
    "layout = go.Layout(title = \"Comparing the Results of Random Forest and LSTM models with the Real Price\",\n",
    "                   width = 1000, height = 600)\n",
    "\n",
    "fig = go.Figure(data = [trace1, trace2, trace3], layout = layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the graph above, we can see that both models did a very good job in this forecast task.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Results in S3, to be consumed by business users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_set_df = X_test_rf\n",
    "result_set_df\n",
    "\n",
    "real_price_array = y_test_rf[0]\n",
    "real_price_array\n",
    "real_price_df = pd.DataFrame(real_price_array, columns = ['real_price'])\n",
    "\n",
    "predicted_price_array = prediction_tf\n",
    "predicted_price_array\n",
    "predicted_price_df = pd.DataFrame(predicted_price_array, columns = ['predicted_price'])\n",
    "predicted_price_df\n",
    "\n",
    "result_set_df['real_price'] = real_price_df.values\n",
    "result_set_df['predicted_price'] = predicted_price_df.values\n",
    "result_set_df['ticker'] = 'JAJIL.CQ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_set_df.to_parquet(f's3://{lab_data_bucket_name}/finance/predictions/predictions.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "[1] https://medium.datadriveninvestor.com/using-aws-sagemaker-to-stock-price-forecast-of-brazilian-commodity-based-companies-f937572b7654\n",
    "[2] https://en.wikipedia.org/wiki/Fundamental_analysis#The_two_analytical_models  \n",
    "[3] https://en.wikipedia.org/wiki/Technical_analysis  \n",
    "[4] https://www.thebalance.com/brazil-and-commodities-808912  \n",
    "[5] https://www.nasdaq.com/articles/3-reasons-why-commodities-etfs-may-rally-in-2021-2021-01-15  \n",
    "[6] https://www.reuters.com/article/column-russell-commodities-yearahead-idUSL1N2IQ0A2    \n",
    "[7] https://plusmining.com/en/commodities-rally-is-projected-to-2021-the-coronavirus-would-mark-a-milestone-in-the-cycle-potentially-leaving-years-of-weak-prices-behind/  \n",
    "[8] https://www.fxempire.com/forecasts/article/speculators-bet-on-a-continued-commodity-rally-in-2021-690009  \n",
    "[9] https://www.kaggle.com/miracl16/tesla-stock-price-prediction-lstm-vs-gru     \n",
    "[10] https://www.kaggle.com/fatmakursun/tesla-stock-price-prediction  \n",
    "[11] https://www.kaggle.com/akanksha496/stock-price-prediction-lstm   \n",
    "[12] https://www.kaggle.com/raoulma/ny-stock-price-prediction-rnn-lstm-gru  \n",
    "[13] https://www.kaggle.com/biphili/time-series-data-analysis-stock-price-code-12#5.Forecasting-Stock-Price   \n",
    "[14] https://towardsdatascience.com/python-for-finance-stock-portfolio-analyses-6da4c3e61054\n"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
