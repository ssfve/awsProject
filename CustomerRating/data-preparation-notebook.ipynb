{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation Notebook\n",
    "\n",
    "In this notebook, you will execute code to \n",
    "\n",
    "1. Download raw data from a DynamoDB table.\n",
    "2. Review the data that will be used to create a machine learning (ML) model.\n",
    "4. Split the data into training and testing sets.\n",
    "5. Perform negative sampling.\n",
    "6. Calculate statistics needed to train the Neural Collaborative Filtering (NCF) model.\n",
    "7. Upload the training and testing data back to an S3 bucket."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Retrieve the raw data from the DynamoDB ratings table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################\n",
    "## Code Cell 1 ##\n",
    "#################\n",
    "import boto3\n",
    "import botocore\n",
    "from boto3.dynamodb.conditions import Attr\n",
    "\n",
    "def do_table_scan():\n",
    "    dynamodb = boto3.resource('dynamodb')\n",
    "    table = dynamodb.Table('ratings')\n",
    "    response = table.scan()\n",
    "    result = response['Items']\n",
    "    while 'LastEvaluatedKey' in response:\n",
    "        response=table.scan(ExclusiveStartKey=response['LastEvaluatedKey'])\n",
    "        result.extend(response['Items'])\n",
    "    \n",
    "    return result\n",
    "    \n",
    "response=do_table_scan()    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this model, we will be using the raw data that contains 4 columns, and has been adapted from a publicly available source for the purposes of this lab. \n",
    "To learn more about the origin of this data set right-click the README.md and choose Open with Markdown preview.\n",
    "- CustomerId\n",
    "- ProductId\n",
    "- rating\n",
    "- ProductName\n",
    "- timestamp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read data into a Pandas dataframe object then split into train and test data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "## Code Cell 2 ##\n",
    "#################\n",
    "\n",
    "# required libraries\n",
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Read the response object into a Pandas DataFrame\n",
    "df = pd.DataFrame(response)\n",
    "\n",
    "# let's see what the data looks like:\n",
    "display(df)\n",
    "\n",
    "# We don't need the ProductName data during training so store it\n",
    "# locally and we will add back to the prediction results later\n",
    "# Using the pickle library for serializing into a byte stream.\n",
    "df_products = df[['ProductId','ProductName']]\n",
    "df_unique_products = df_products.drop_duplicates(subset=['ProductId'])\n",
    "df_unique_products.to_pickle('products.pkl')\n",
    "\n",
    "# Understand what should be the maximum sampling size for each customer:\n",
    "df.groupby('CustomerId').ProductId.nunique().min()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: Since the \"least active\" customer has 20 ratings, for our testing set, let's sample 50% for every customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "## Code Cell 3 ##\n",
    "#################\n",
    "\n",
    "# The below code defines a function to be used in the next code cell to split the \n",
    "# DataFrame into training and testing data sets.\n",
    "\n",
    "def train_test_split(df, sampling_num):\n",
    "    \"\"\" perform training/testing split\n",
    "    \n",
    "    @param df: dataframe\n",
    "    @param sampling_num: number of ratings to sample for each customer\n",
    "    \n",
    "    @return df_train: training data\n",
    "    @return df_test testing data\n",
    "    \n",
    "    \"\"\"\n",
    "    # first sort the data by time\n",
    "    df = df.sort_values(['CustomerId', 'timestamp'], ascending=[True, False])\n",
    "    \n",
    "    # perform deep copy on the dataframe to avoid modification on the original dataframe\n",
    "    df_train = df.copy(deep=True)\n",
    "    df_test = df.copy(deep=True)\n",
    "    \n",
    "    # get test set\n",
    "    df_test = df_test.groupby(['CustomerId']).head(sampling_num).reset_index()\n",
    "    \n",
    "    # get train set\n",
    "    df_train = df_train.merge(\n",
    "        df_test[['CustomerId', 'ProductId']].assign(remove=1),\n",
    "        how='left'\n",
    "    ).query('remove != 1').drop(columns='remove').reset_index(drop=True)\n",
    "    \n",
    "    # sanity check to make sure we're not duplicating/losing data\n",
    "    assert len(df) == len(df_train) + len(df_test)\n",
    "    \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "## Code Cell 4 ##\n",
    "#################\n",
    "\n",
    "# This code snippet calls the above function and passes two parameters: the dataframe and the sampling size.\n",
    "\n",
    "df_train, df_test = train_test_split(df, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Perform negative sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming if a user rating an item is a positive label, there is no negative sample in the dataset, which is not possible for model training. Therefore, we random sample `n` items from the unseen product list for every customer to provide the negative samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "## Code Cell 5 ##\n",
    "#################\n",
    "\n",
    "def negative_sampling(customer_ids, product_ids, items, n_neg):\n",
    "    \"\"\"This function creates n_neg negative labels for every positive label\n",
    "    \n",
    "    @param customer_ids: list of customer ids\n",
    "    @param product_ids: list of product ids\n",
    "    @param items: unique list of product ids\n",
    "    @param n_neg: number of negative labels to sample\n",
    "    \n",
    "    @return df_neg: negative sample dataframe\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    neg = []\n",
    "    ui_pairs = zip(customer_ids, product_ids)\n",
    "    records = set(ui_pairs)\n",
    "    \n",
    "    # for every positive label case\n",
    "    for (u, i) in records:\n",
    "        # generate n_neg negative labels\n",
    "        for _ in range(n_neg):\n",
    "            # if the randomly sampled product exists for that customer\n",
    "            j = np.random.choice(items)\n",
    "            while(u, j) in records:\n",
    "                # resample\n",
    "                j = np.random.choice(items)\n",
    "            neg.append([u, j, 0])\n",
    "    # conver to pandas dataframe for concatenation later\n",
    "    df_neg = pd.DataFrame(neg, columns=['CustomerId', 'ProductId', 'rating'])\n",
    "    \n",
    "    return df_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "## Code Cell 6 ##\n",
    "#################\n",
    "\n",
    "# create and display the negative samples for training set\n",
    "neg_train = negative_sampling(\n",
    "    customer_ids=df_train.CustomerId.values, \n",
    "    product_ids=df_train.ProductId.values,\n",
    "    items=df.ProductId.unique(),\n",
    "    n_neg=5\n",
    ")\n",
    "\n",
    "print(f'created {neg_train.shape[0]:,} negative samples')\n",
    "\n",
    "df_train = df_train[['CustomerId', 'ProductId']].assign(rating=1)\n",
    "df_test = df_test[['CustomerId', 'ProductId']].assign(rating=1)\n",
    "\n",
    "df_train = pd.concat([df_train, neg_train], ignore_index=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate statistics for our understanding and model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "## Code Cell 7 ##\n",
    "#################\n",
    "\n",
    "def get_unique_count(df):\n",
    "    \"\"\"calculate unique customer and product counts\"\"\"\n",
    "    return df.CustomerId.nunique(), df.ProductId.nunique()\n",
    "\n",
    "# unique number of customers and products in the whole dataset\n",
    "get_unique_count(df)\n",
    "\n",
    "print('training set shape', get_unique_count(df_train))\n",
    "print('testing set shape', get_unique_count(df_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we calculate some statistics for training purposes. We also store the number of customers and product ids to be used during model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "## Code Cell 8  ##\n",
    "##################\n",
    "\n",
    "# number of unique user and number of unique customer/products\n",
    "n_customer, n_product = get_unique_count(df_train)\n",
    "\n",
    "print(\"number of unique customers \", n_customer)\n",
    "print(\"number of unique products \", n_product)\n",
    "\n",
    "# save the variable for the model training notebook\n",
    "# -----\n",
    "# read about `store` magic here: \n",
    "# https://ipython.readthedocs.io/en/stable/config/extensions/storemagic.html\n",
    "\n",
    "%store n_customer\n",
    "%store n_product\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Preprocess the data and upload it to the S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "## Code Cell 9  ##\n",
    "##################\n",
    "\n",
    "# get current session region\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "print(f'currently in {region}')\n",
    "\n",
    "# use the default sagemaker s3 bucket to store processed data\n",
    "# here we figure out what that default bucket name is \n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "print(bucket_name)  # bucket name format: \"sagemaker-{region}-{aws_account_id}\"\n",
    "\n",
    "# Save data locallly \n",
    "dest = 'data/'\n",
    "train_path = os.path.join(dest, 'train.npy')\n",
    "test_path = os.path.join(dest, 'test.npy')\n",
    "\n",
    "!mkdir {dest}\n",
    "np.save(train_path, df_train.values)\n",
    "np.save(test_path, df_test.values)\n",
    "\n",
    "# upload to S3 bucket (see the bucket name above)\n",
    "sagemaker_session.upload_data(train_path, key_prefix='data')\n",
    "sagemaker_session.upload_data(test_path, key_prefix='data')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data preparation completed. Proceed with the next step of the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "25034407fed5d681614dac11a1c0537e8cb49e3a8883c071303eea01322943d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
